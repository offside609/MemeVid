# AI Meme Video Agent

An async AI agent system for generating meme videos with intelligent narrative and caption generation.

## ğŸš€ Features

- **Async Node Architecture**: Modular, scalable agent nodes
- **FastAPI Backend**: High-performance async API
- **AI Integration**: OpenAI, LangChain, LangGraph support
- **In-Memory Persistence**: Fast state management
- **Production Ready**: Proper logging, error handling, monitoring

## ğŸ“ Project Structure

```
MemeVid/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ graphs/              # LangGraph workflows
â”‚   â”œâ”€â”€ nodes/               # Agent nodes
â”‚   â”‚   â”œâ”€â”€ base_node.py     # Base node class
â”‚   â”‚   â”œâ”€â”€ ingest_node.py   # Media ingestion
â”‚   â”‚   â”œâ”€â”€ perception_node.py # Content analysis
â”‚   â”‚   â””â”€â”€ ...              # Other nodes
â”‚   â””â”€â”€ database/            # Database models
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ scripts/                 # Utility scripts
â””â”€â”€ logs/                    # Log files
```

## ğŸ› ï¸ Setup

### Prerequisites
- Python 3.11+
- Conda environment
- OpenAI API key

### Installation

1. **Clone and navigate to project**
   ```bash
   cd MemeVid
   ```

2. **Activate conda environment**
   ```bash
   conda activate your_env_name
   ```

3. **Install dependencies**
   ```bash
   # Production dependencies
   pip install -r requirements.txt

   # Development dependencies
   pip install -r requirements-dev.txt
   ```

4. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

5. **Run the application**
   ```bash
   uvicorn app:app --reload --port 8000

6. **Curl for getting output
   curl -X POST http://localhost:8000/jokestruc/generate \
  -H "Content-Type: application/json" \
  -d '{
        "media_path": "/Users/admin/Documents/MemeVid/workflows/Jokestruc/zostel_demo_video.mp4"
      }'

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=backend

# Run specific test file
pytest tests/test_main.py
```

## ğŸ“š Documentation

- [API Documentation](docs/API.md) - Complete API reference with examples
- [Development Guide](docs/DEVELOPMENT.md) - Setup, architecture, and contribution guide
- [Project Structure](#-project-structure) - Overview of code organization

## ğŸ“š API Documentation

Once running, visit:
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## ğŸ”§ Development

### Code Quality
```bash
# Format code
black backend/ tests/

# Lint code
flake8 backend/

# Type checking
mypy backend/
```

### Pre-commit Hooks
```bash
# Install pre-commit
pre-commit install

# Run manually
pre-commit run --all-files
```

## ğŸš€ Deployment

### Production Setup
1. Set production environment variables
2. Configure database (PostgreSQL/Redis)
3. Set up monitoring (LangSmith)
4. Deploy with Docker/Gunicorn

### Environment Variables
```bash
# Required
OPENAI_API_KEY=your_openai_key

# Optional
DEBUG=False
LOG_LEVEL=INFO
REDIS_URL=redis://localhost:6379/0
```

## ğŸ¤– Agent Architecture

### Node Types
- **IngestNode**: Media file processing
- **PerceptionNode**: Content analysis
- **NarrativeNode**: Story generation
- **TemplateNode**: Template selection
- **CaptionNode**: Caption generation
- **RenderNode**: Video rendering

### Workflow
1. **Ingest** â†’ Process media input
2. **Perceive** â†’ Analyze content
3. **Narrate** â†’ Generate storyline
4. **Template** â†’ Select meme template
5. **Caption** â†’ Generate captions
6. **Render** â†’ Create final video

## ğŸ“Š Monitoring

- **LangSmith**: AI workflow tracing
- **Logs**: Structured logging
- **Metrics**: Performance tracking
- **Health**: System status

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Make changes
4. Run tests
5. Submit pull request

## ğŸ“„ License

MIT License - see LICENSE file for details
